// NOMA TTA - Test-Time Adaptation with LoRA (Optimized)
// Evaluates backbone on stream WITH online adaptation after drift detection
// 
// Protocol:
// 1. Load frozen backbone weights
// 2. Evaluate clean phase with frozen backbone (no LoRA)
// 3. At t0 (drift detection), inject LoRA adapter on last layer
// 4. Train LoRA on drift data and evaluate with adapted model
// 5. Save both phases separately for proper temporal metrics
//
// LoRA Implementation:
// Original: y = xW2 + b2
// With LoRA: y = xW2 + x(A*B) + b2  where A:[in,rank], B:[rank,out]
// Initialized to zero: A*B = 0, so output unchanged at injection

fn main() {
    let optimizer = 2.0;       // Adam for online updates
    let learning_rate = 0.01;  // Higher LR for fast adaptation
    let beta1 = 0.9;
    let beta2 = 0.999;
    let epsilon = 0.00000001;

    print("=== NOMA TTA - Online Adaptation with LoRA ===");
    
    // =========================================================================
    // Load Frozen Backbone Weights (these will NOT be updated)
    // =========================================================================
    print("Loading frozen backbone weights...");
    load_safetensors_named W1 = "noma_TTA/output/backbone_weights.safetensors" : "W1";
    load_safetensors_named b1 = "noma_TTA/output/backbone_weights.safetensors" : "b1";
    load_safetensors_named W2 = "noma_TTA/output/backbone_weights.safetensors" : "W2";
    load_safetensors_named b2 = "noma_TTA/output/backbone_weights.safetensors" : "b2";
    
    // Store original backbone checksum for verification (compute once)
    let backbone_checksum = sum(W1 * W1) + sum(W2 * W2);
    print("Backbone loaded. Initial checksum:");
    print(backbone_checksum);
    
    // =========================================================================
    // Initialize LoRA Adapter for Last Layer (W2: 128 -> 10)
    // LoRA: delta_W = A @ B where A:[128, rank], B:[rank, 10]
    // Initialize A to small random, B to zeros -> A@B = 0 (neutral injection)
    // =========================================================================
    
    // LoRA matrices - these are LEARNABLE and will be updated
    // A: small random initialization
    // B: zero initialization -> ensures A@B = 0 at injection
    learn lora_A = rand_tensor(128.0, 4.0) * 0.01;  // [128, 4]
    learn lora_B = rand_tensor(4.0, 10.0) * 0.0;    // [4, 10] = zeros
    
    print("LoRA adapter initialized (rank=4, neutral injection).");
    
    // =========================================================================
    // Load Phase Data Separately
    // =========================================================================
    print("Loading streaming data...");
    
    load_safetensors_named X_clean = "noma_TTA/data/stream_clean.safetensors" : "x";
    load_safetensors_named Y_clean_labels = "noma_TTA/data/stream_clean.safetensors" : "y";
    load_safetensors_named T_clean = "noma_TTA/data/stream_clean.safetensors" : "t";
    load_safetensors_named Phase_clean = "noma_TTA/data/stream_clean.safetensors" : "phase";
    load_safetensors_named Intensity_clean = "noma_TTA/data/stream_clean.safetensors" : "intensity";
    
    load_safetensors_named X_drift = "noma_TTA/data/stream_drift.safetensors" : "x";
    load_safetensors_named Y_drift = "noma_TTA/data/stream_drift.safetensors" : "y_onehot";
    load_safetensors_named Y_drift_labels = "noma_TTA/data/stream_drift.safetensors" : "y";
    load_safetensors_named T_drift = "noma_TTA/data/stream_drift.safetensors" : "t";
    load_safetensors_named Phase_drift = "noma_TTA/data/stream_drift.safetensors" : "phase";
    load_safetensors_named Intensity_drift = "noma_TTA/data/stream_drift.safetensors" : "intensity";
    
    print("Stream loaded: 30000 clean + 30000 drift samples");
    
    // =========================================================================
    // Phase 1: Clean Phase - Evaluate with frozen backbone (NO LoRA)
    // =========================================================================
    print("Phase 1: Evaluating clean data with frozen backbone...");
    
    let z1_clean = matmul(X_clean, W1) + b1;
    let h1_clean = relu(z1_clean);
    let z2_clean = matmul(h1_clean, W2) + b2;
    let pred_clean = softmax(z2_clean);
    
    print("Clean phase evaluation complete (frozen backbone, no LoRA).");
    
    // =========================================================================
    // Phase 2: Drift Phase with TTA (t >= 30000)
    // Inject LoRA adapter and perform online updates
    // =========================================================================
    print("Phase 2: Drift detected! Activating LoRA adaptation...");
    print("Injection point: t = 30000");
    
    // Online adaptation loop: process drift data with updates
    // Large batch size for efficiency (30000 samples / 512 = ~59 batches)
    let batch_size = 512.0;
    let epochs = 1.0;  // Single pass through data (true online learning)
    
    print("Starting online adaptation (batch_size=512)...");
    
    epoch epochs batch X_drift, Y_drift with batch_size -> x_batch, y_batch {
        // Forward pass with LoRA
        // Layer 1: frozen backbone
        let z1 = matmul(x_batch, W1) + b1;
        let h1 = relu(z1);
        
        // Layer 2: backbone + LoRA adapter
        // With LoRA: z2 = h1 @ W2 + h1 @ (lora_A @ lora_B) + b2
        let lora_delta = matmul(lora_A, lora_B);  // [128, 10]
        let z2 = matmul(h1, W2) + matmul(h1, lora_delta) + b2;
        let pred = softmax(z2);
        
        // Supervised loss (using available labels for online feedback)
        let error = pred - y_batch;
        let loss = mean(error * error);
        
        // Only LoRA parameters are marked as 'learn', so only they update
        minimize loss;
    }
    
    print("TTA adaptation complete.");
    
    // =========================================================================
    // Get Final Predictions on Drift Data WITH Adapted LoRA
    // =========================================================================
    print("Computing drift predictions with adapted LoRA...");
    
    let z1_drift = matmul(X_drift, W1) + b1;
    let h1_drift = relu(z1_drift);
    let lora_delta_final = matmul(lora_A, lora_B);
    let z2_drift = matmul(h1_drift, W2) + matmul(h1_drift, lora_delta_final) + b2;
    let pred_drift = softmax(z2_drift);
    
    print("Drift phase predictions complete.");
    
    // =========================================================================
    // Verify Backbone Integrity
    // =========================================================================
    let backbone_checksum_final = sum(W1 * W1) + sum(W2 * W2);
    let checksum_diff = abs(backbone_checksum_final - backbone_checksum);
    
    print("Backbone checksum verification:");
    print("  Initial checksum:");
    print(backbone_checksum);
    print("  Final checksum:");
    print(backbone_checksum_final);
    print("  Difference (should be 0):");
    print(checksum_diff);
    
    // =========================================================================
    // Save Results - Separate files for clean and drift phases
    // This allows proper temporal combination in post-processing
    // =========================================================================
    print("Saving TTA results...");
    
    // Save clean phase (evaluated with frozen backbone, no LoRA)
    save_safetensors {
        pred_probs: pred_clean,
        y_true: Y_clean_labels,
        t: T_clean,
        phase: Phase_clean,
        intensity: Intensity_clean
    }, "noma_TTA/output/eval_tta_clean.safetensors";
    
    // Save drift phase (evaluated with adapted LoRA)
    save_safetensors {
        pred_probs: pred_drift,
        y_true: Y_drift_labels,
        t: T_drift,
        phase: Phase_drift,
        intensity: Intensity_drift,
        lora_A: lora_A,
        lora_B: lora_B,
        backbone_checksum_initial: backbone_checksum,
        backbone_checksum_final: backbone_checksum_final
    }, "noma_TTA/output/eval_tta_drift.safetensors";
    
    print("Results saved to:");
    print("  - noma_TTA/output/eval_tta_clean.safetensors (frozen backbone)");
    print("  - noma_TTA/output/eval_tta_drift.safetensors (with adapted LoRA)");
    print("=== TTA Evaluation Complete ===");
    
    return 0.0;
}
